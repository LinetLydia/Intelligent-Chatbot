{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40b4fa9-fda3-4769-a26a-43894f3e153b",
   "metadata": {},
   "source": [
    "# Intelligent Chatbot Development Project\n",
    "\n",
    "## Introduction\n",
    "This project builds a Smart Career Guidance Chatbot that:\n",
    "- Understands user intent (e.g., “skills for data analyst”).\n",
    "- Extracts entities (job titles, tools, skills).\n",
    "- Retrieves or generates helpful responses.\n",
    "- Adapts tone with basic sentiment awareness.\n",
    "\n",
    "### Goals\n",
    "1. Create a clean, reproducible notebook pipeline.\n",
    "2. Start with a **retrieval-first** chatbot (fast, controllable).\n",
    "3. Add NER + sentiment to personalize replies.\n",
    "4. Keep everything version-controlled with Git.\n",
    "\n",
    "### Milestones\n",
    "- **M1:** Data loading + text cleaning\n",
    "- **M2:** Embeddings + retrieval\n",
    "- **M3:** Intent classifier (baseline)\n",
    "- **M4:** NER + sentiment integration\n",
    "- **M5:** Simple UI (Gradio) for demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d010d676-5377-46c0-980b-9d43ce991e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet numpy pandas scikit-learn nltk spacy \"sentence-transformers>=3.0.0\" transformers gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7f5e8e-ea1f-493a-81d2-0ecbe093b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, sys\n",
    "# Downloading of small NLTK packs\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "import spacy\n",
    "try:\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a577b89-f272-4980-819e-fc705e8bbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\hp\\miniconda3\\lib\\site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d4e6e-5f00-43bd-bcb5-d84339d9693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\miniconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.16 | OS: Windows\n",
      "numpy                  -> 2.0.2\n",
      "pandas                 -> 2.2.3\n",
      "sentence-transformers  -> OK\n",
      "transformers           -> OK\n",
      "spacy                  -> 3.8.7\n",
      "nltk                   -> 3.9.2\n",
      "Embeddings shape: (2, 384)\n"
     ]
    }
   ],
   "source": [
    "import tf_keras as keras\n",
    "import sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import nltk, spacy\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| OS:\", platform.system())\n",
    "for name, mod in [\n",
    "    (\"numpy\", np), (\"pandas\", pd),\n",
    "    (\"sentence-transformers\", SentenceTransformer),\n",
    "    (\"transformers\", AutoTokenizer),\n",
    "    (\"spacy\", spacy), (\"nltk\", nltk),\n",
    "]:\n",
    "    try:\n",
    "        v = mod.__version__ if hasattr(mod, \"__version__\") else \"OK\"\n",
    "    except Exception:\n",
    "        v = \"OK\"\n",
    "    print(f\"{name:22s} -> {v}\")\n",
    "\n",
    "# Quick sanity check: load a tiny embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "sample = [\"hello world\", \"career in data science\"]\n",
    "emb = embedder.encode(sample, normalize_embeddings=True)\n",
    "print(\"Embeddings shape:\", emb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fc9db-8186-41f6-8d3e-8bbf14238b53",
   "metadata": {},
   "source": [
    "## Step 2 — Data Setup (2A: toy dataset)\n",
    "We’ll create a tiny in-notebook dataset to verify our flow before using a real Kaggle dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1078a7d4-c94b-442c-b71c-4304d61f9bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>[What skills do I need for data science?, How ...</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>[What do I need to study for AI?, What are AI ...</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>[What job is good for me if I like numbers?, I...</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>[Where should I start learning data analysis?,...</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>[Hi, Hello, Hey]</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>[Bye, See you later, Goodbye]</td>\n",
       "      <td>Goodbye! Keep learning and stay curious!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        intent  \\\n",
       "0  ask_skills_for_data_science   \n",
       "1            ask_skills_for_ai   \n",
       "2       ask_job_recommendation   \n",
       "3            ask_learning_path   \n",
       "4                     greeting   \n",
       "5                      goodbye   \n",
       "\n",
       "                                            patterns  \\\n",
       "0  [What skills do I need for data science?, How ...   \n",
       "1  [What do I need to study for AI?, What are AI ...   \n",
       "2  [What job is good for me if I like numbers?, I...   \n",
       "3  [Where should I start learning data analysis?,...   \n",
       "4                                   [Hi, Hello, Hey]   \n",
       "5                      [Bye, See you later, Goodbye]   \n",
       "\n",
       "                                           responses  \n",
       "0  Data Science needs skills like Python, SQL, St...  \n",
       "1  AI requires knowledge of Python, Neural Networ...  \n",
       "2  You might enjoy careers like Data Analyst, Sta...  \n",
       "3  Start with Python, then learn data visualizati...  \n",
       "4                   Hello! How can I help you today?  \n",
       "5           Goodbye! Keep learning and stay curious!  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"intent\": [\n",
    "        \"ask_skills_for_data_science\",\n",
    "        \"ask_skills_for_ai\",\n",
    "        \"ask_job_recommendation\",\n",
    "        \"ask_learning_path\",\n",
    "        \"greeting\",\n",
    "        \"goodbye\",\n",
    "    ],\n",
    "    \"patterns\": [\n",
    "        [\"What skills do I need for data science?\", \"How to become a data scientist?\"],\n",
    "        [\"What do I need to study for AI?\", \"What are AI skills?\"],\n",
    "        [\"What job is good for me if I like numbers?\", \"I enjoy problem-solving, any job ideas?\"],\n",
    "        [\"Where should I start learning data analysis?\", \"Best way to learn machine learning?\"],\n",
    "        [\"Hi\", \"Hello\", \"Hey\"],\n",
    "        [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "    ],\n",
    "    \"responses\": [\n",
    "        \"Data Science needs skills like Python, SQL, Statistics, and Machine Learning.\",\n",
    "        \"AI requires knowledge of Python, Neural Networks, and Data Modeling.\",\n",
    "        \"You might enjoy careers like Data Analyst, Statistician, or Research Scientist.\",\n",
    "        \"Start with Python, then learn data visualization and basic machine learning.\",\n",
    "        \"Hello! How can I help you today?\",\n",
    "        \"Goodbye! Keep learning and stay curious!\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcacc4e3-4738-4002-a5a7-7f849479aadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What skills do I need for data science?</td>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to become a data scientist?</td>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do I need to study for AI?</td>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are AI skills?</td>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What job is good for me if I like numbers?</td>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I enjoy problem-solving, any job ideas?</td>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Where should I start learning data analysis?</td>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best way to learn machine learning?</td>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text                       intent  \\\n",
       "0       What skills do I need for data science?  ask_skills_for_data_science   \n",
       "1               How to become a data scientist?  ask_skills_for_data_science   \n",
       "2               What do I need to study for AI?            ask_skills_for_ai   \n",
       "3                           What are AI skills?            ask_skills_for_ai   \n",
       "4    What job is good for me if I like numbers?       ask_job_recommendation   \n",
       "5       I enjoy problem-solving, any job ideas?       ask_job_recommendation   \n",
       "6  Where should I start learning data analysis?            ask_learning_path   \n",
       "7           Best way to learn machine learning?            ask_learning_path   \n",
       "8                                            Hi                     greeting   \n",
       "9                                         Hello                     greeting   \n",
       "\n",
       "                                            response  \n",
       "0  Data Science needs skills like Python, SQL, St...  \n",
       "1  Data Science needs skills like Python, SQL, St...  \n",
       "2  AI requires knowledge of Python, Neural Networ...  \n",
       "3  AI requires knowledge of Python, Neural Networ...  \n",
       "4  You might enjoy careers like Data Analyst, Sta...  \n",
       "5  You might enjoy careers like Data Analyst, Sta...  \n",
       "6  Start with Python, then learn data visualizati...  \n",
       "7  Start with Python, then learn data visualizati...  \n",
       "8                   Hello! How can I help you today?  \n",
       "9                   Hello! How can I help you today?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    for pattern in row[\"patterns\"]:\n",
    "        rows.append({\"text\": pattern, \"intent\": row[\"intent\"], \"response\": row[\"responses\"]})\n",
    "\n",
    "chatbot_df = pd.DataFrame(rows)\n",
    "chatbot_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0465e62-2136-4052-bca5-c10f00ad4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: chatbot_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "chatbot_df.to_csv(\"chatbot_dataset.csv\", index=False)\n",
    "print(\"Saved: chatbot_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593f1b97-b2d4-4e54-a684-8c4d56d77205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\hp\\miniconda3\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fc66e3-824f-4bba-a50f-814cd322879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle config dir: C:\\Users\\hp\\projects\\intelligent-chatbot-notebook\\.kaggle\n",
      "Has kaggle.json: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.join(os.getcwd(), \".kaggle\")\n",
    "# Optional check:\n",
    "print(\"Kaggle config dir:\", os.environ[\"KAGGLE_CONFIG_DIR\"])\n",
    "print(\"Has kaggle.json:\", os.path.exists(os.path.join(os.environ[\"KAGGLE_CONFIG_DIR\"], \"kaggle.json\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68b5105-0419-4d40-90ab-6030e14757dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/elvinagammed/chatbots-intent-recognition-dataset\n",
      "License(s): copyright-authors\n",
      "chatbots-intent-recognition-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d elvinagammed/chatbots-intent-recognition-dataset -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384ba518-f855-47ed-8ee1-6d75795682cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files:\n",
      "data\\chatbots-intent-recognition-dataset.zip\n",
      "data\\Intent.json\n"
     ]
    }
   ],
   "source": [
    "import zipfile, glob\n",
    "\n",
    "zip_path = sorted(glob.glob(\"data/*.zip\"))[0]\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(\"data\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "for p in glob.glob(\"data/**/*\", recursive=True):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f65be7-ca5e-4b37-83b5-0b2ce6eb261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intents']\n",
      "[{'context': {'clear': False, 'in': '', 'out': 'GreetingUserRequest'},\n",
      "  'entities': [],\n",
      "  'entityType': 'NA',\n",
      "  'extension': {'entities': False, 'function': '', 'responses': []},\n",
      "  'intent': 'Greeting',\n",
      "  'responses': ['Hi human, please tell me your GeniSys user',\n",
      "                'Hello human, please tell me your GeniSys user',\n",
      "                'Hola human, please tell me your GeniSys user'],\n",
      "  'text': ['Hi',\n",
      "           'Hi there',\n",
      "           'Hola',\n",
      "           'Hello',\n",
      "           'Hello there',\n",
      "           'Hya',\n",
      "           'Hya there']},\n",
      " {'context': {'clear': True, 'in': 'GreetingUserRequest', 'out': ''},\n",
      "  'entities': [{'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3}],\n",
      "  'entityType': 'NA',\n",
      "  'extension': {'entities': True,\n",
      "                'function': 'extensions.gHumans.updateHuman',\n",
      "                'responses': ['Hi %%HUMAN%%! How can I help?',\n",
      "                              'Hi %%HUMAN%%, how can I help you?',\n",
      "                              'Hello %%HUMAN%%, what can I do for you?',\n",
      "                              'Hola %%HUMAN%%, how can I help you?',\n",
      "                              'OK hi %%HUMAN%%, what can I do for you?']},\n",
      "  'intent': 'GreetingResponse',\n",
      "  'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
      "                'Good! Hi <HUMAN>, how can I help you?',\n",
      "                'Cool! Hello <HUMAN>, what can I do for you?',\n",
      "                'OK! Hola <HUMAN>, how can I help you?',\n",
      "                'OK! hi <HUMAN>, what can I do for you?'],\n",
      "  'text': ['My user is Adam',\n",
      "           'This is Adam',\n",
      "           'I am Adam',\n",
      "           'It is Adam',\n",
      "           'My user is Bella',\n",
      "           'This is Bella',\n",
      "           'I am Bella',\n",
      "           'It is Bella']}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: Load and preview the JSON\n",
    "with open(\"data/Intent.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Show the first few items so we can inspect structure\n",
    "if isinstance(data, dict):\n",
    "    # If it's a dictionary, show keys and sample content\n",
    "    pprint(list(data.keys()))\n",
    "    if \"intents\" in data:\n",
    "        pprint(data[\"intents\"][:2])\n",
    "    else:\n",
    "        pprint(data)\n",
    "else:\n",
    "    # If it's a list, show first 2 items\n",
    "    pprint(data[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1adf4bb-1e12-4a8c-b3ad-76b2b7e2a006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hola</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hello there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hya</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hya there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>My user is Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>This is Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>I am Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             intent          pattern  \\\n",
       "0          Greeting               Hi   \n",
       "1          Greeting         Hi there   \n",
       "2          Greeting             Hola   \n",
       "3          Greeting            Hello   \n",
       "4          Greeting      Hello there   \n",
       "5          Greeting              Hya   \n",
       "6          Greeting        Hya there   \n",
       "7  GreetingResponse  My user is Adam   \n",
       "8  GreetingResponse     This is Adam   \n",
       "9  GreetingResponse        I am Adam   \n",
       "\n",
       "                                     response  \n",
       "0  Hi human, please tell me your GeniSys user  \n",
       "1  Hi human, please tell me your GeniSys user  \n",
       "2  Hi human, please tell me your GeniSys user  \n",
       "3  Hi human, please tell me your GeniSys user  \n",
       "4  Hi human, please tell me your GeniSys user  \n",
       "5  Hi human, please tell me your GeniSys user  \n",
       "6  Hi human, please tell me your GeniSys user  \n",
       "7          Great! Hi <HUMAN>! How can I help?  \n",
       "8          Great! Hi <HUMAN>! How can I help?  \n",
       "9          Great! Hi <HUMAN>! How can I help?  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for intent in data[\"intents\"]:\n",
    "    intent_name = intent.get(\"intent\", \"unknown\")\n",
    "    patterns = intent.get(\"text\", [])\n",
    "    responses = intent.get(\"responses\", [])\n",
    "    \n",
    "    # Make one row per text pattern\n",
    "    for pattern in patterns:\n",
    "        rows.append({\n",
    "            \"intent\": intent_name,\n",
    "            \"pattern\": pattern,\n",
    "            \"response\": responses[0] if responses else None\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392bb82e-c503-49cb-bc6c-3f978d7bf6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset as chatbot_intents_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"chatbot_intents_dataset.csv\", index=False)\n",
    "print(\"Saved cleaned dataset as chatbot_intents_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe87f6e-2984-4968-a932-f60627051ef7",
   "metadata": {},
   "source": [
    "## Step 3 — Embeddings and Retrieval\n",
    "\n",
    "We’ll use a pre-trained SentenceTransformer model to create text embeddings for each pattern.\n",
    "These embeddings represent the meaning of text as numeric vectors.\n",
    "When a user sends a query, the chatbot will:\n",
    "1. Convert the query into an embedding,\n",
    "2. Compare it with all existing pattern embeddings using cosine similarity,\n",
    "3. Retrieve the most relevant response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea403c24-6ffa-4953-af27-bc5cfbbcdbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "      <td>[-0.09047622978687286, 0.04043959826231003, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "      <td>[-0.10393176972866058, 0.020045580342411995, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hola</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "      <td>[-0.06515946239233017, 0.09274395555257797, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     intent   pattern                                    response  \\\n",
       "0  Greeting        Hi  Hi human, please tell me your GeniSys user   \n",
       "1  Greeting  Hi there  Hi human, please tell me your GeniSys user   \n",
       "2  Greeting      Hola  Hi human, please tell me your GeniSys user   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.09047622978687286, 0.04043959826231003, 0....  \n",
       "1  [-0.10393176972866058, 0.020045580342411995, 0...  \n",
       "2  [-0.06515946239233017, 0.09274395555257797, -0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(df[\"pattern\"].tolist(), normalize_embeddings=True)\n",
    "\n",
    "df[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "# Sample\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a3cb97-aa8b-45e2-936c-3dfb58ff40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_response(user_input, df, model):\n",
    "    # Step 1: Encode user query\n",
    "    query_emb = model.encode([user_input], normalize_embeddings=True)\n",
    "    \n",
    "    # Step 2: Compute cosine similarity with existing embeddings\n",
    "    similarities = cosine_similarity(query_emb, np.vstack(df[\"embedding\"].values))[0]\n",
    "    \n",
    "    # Step 3: Pick the highest similarity\n",
    "    best_idx = np.argmax(similarities)\n",
    "    \n",
    "    # Step 4: Return intent, response, and similarity score\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"predicted_intent\": df.iloc[best_idx][\"intent\"],\n",
    "        \"response\": df.iloc[best_idx][\"response\"],\n",
    "        \"similarity\": round(similarities[best_idx], 3)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d8097dc-1bb9-447f-81f0-830903146221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗣️ User: hello there\n",
      "🤖 Bot (Greeting): Hi human, please tell me your GeniSys user\n",
      "Similarity: 1.0\n",
      "\n",
      "🗣️ User: who are you\n",
      "🤖 Bot (NameQuery): You can call me Geni\n",
      "Similarity: 0.821\n",
      "\n",
      "🗣️ User: bye\n",
      "🤖 Bot (GoodBye): See you later\n",
      "Similarity: 1.0\n",
      "\n",
      "🗣️ User: what can you do\n",
      "🤖 Bot (PodBayDoorResponse): It is classified, I could tell you but I would have to kill you!\n",
      "Similarity: 0.455\n",
      "\n",
      "🗣️ User: hi human\n",
      "🤖 Bot (Greeting): Hi human, please tell me your GeniSys user\n",
      "Similarity: 0.659\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"hello there\",\n",
    "    \"who are you\",\n",
    "    \"bye\",\n",
    "    \"what can you do\",\n",
    "    \"hi human\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    result = get_response(q, df, model)\n",
    "    print(f\"\\n🗣️ User: {result['user_input']}\")\n",
    "    print(f\"🤖 Bot ({result['predicted_intent']}): {result['response']}\")\n",
    "    print(f\"Similarity: {result['similarity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55a39d4-ed03-4b4e-b92d-5f8019e83c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset with embeddings.\n"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"chatbot_with_embeddings.pkl\")\n",
    "print(\"Saved dataset with embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232a58e-4339-4ef5-a821-d44b09a35787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
