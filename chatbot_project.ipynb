{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40b4fa9-fda3-4769-a26a-43894f3e153b",
   "metadata": {},
   "source": [
    "# Intelligent Chatbot Development Project\n",
    "\n",
    "## Introduction\n",
    "This project builds a Smart Career Guidance Chatbot that:\n",
    "- Understands user intent (e.g., “skills for data analyst”).\n",
    "- Extracts entities (job titles, tools, skills).\n",
    "- Retrieves or generates helpful responses.\n",
    "- Adapts tone with basic sentiment awareness.\n",
    "\n",
    "### Goals\n",
    "1. Create a clean, reproducible notebook pipeline.\n",
    "2. Start with a **retrieval-first** chatbot (fast, controllable).\n",
    "3. Add NER + sentiment to personalize replies.\n",
    "4. Keep everything version-controlled with Git.\n",
    "\n",
    "### Milestones\n",
    "- **M1:** Data loading + text cleaning\n",
    "- **M2:** Embeddings + retrieval\n",
    "- **M3:** Intent classifier (baseline)\n",
    "- **M4:** NER + sentiment integration\n",
    "- **M5:** Simple UI (Gradio) for demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d010d676-5377-46c0-980b-9d43ce991e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet numpy pandas scikit-learn nltk spacy \"sentence-transformers>=3.0.0\" transformers gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7f5e8e-ea1f-493a-81d2-0ecbe093b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, sys\n",
    "# Downloading of small NLTK packs\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "import spacy\n",
    "try:\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a577b89-f272-4980-819e-fc705e8bbee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Using cached tensorflow-2.20.0-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.70.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached ml_dtypes-0.5.3-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\miniconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Using cached tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorflow-2.20.0-cp310-cp310-win_amd64.whl (331.7 MB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp310-cp310-win_amd64.whl (206 kB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.5 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 967.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 967.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 967.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 967.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 918.0 kB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, ml_dtypes, tensorboard, keras, tensorflow, tf-keras\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: ml_dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.8.0\n",
      "    Uninstalling keras-3.8.0:\n",
      "      Successfully uninstalled keras-3.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "Successfully installed keras-3.12.0 ml_dtypes-0.5.3 protobuf-6.33.0 tensorboard-2.20.0 tensorflow-2.20.0 tf-keras-2.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.3 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\n",
      "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 6.33.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d4e6e-5f00-43bd-bcb5-d84339d9693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\miniconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.16 | OS: Windows\n",
      "numpy                  -> 2.0.2\n",
      "pandas                 -> 2.2.3\n",
      "sentence-transformers  -> OK\n",
      "transformers           -> OK\n",
      "spacy                  -> 3.8.7\n",
      "nltk                   -> 3.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (2, 384)\n"
     ]
    }
   ],
   "source": [
    "import tf_keras as keras\n",
    "import sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import nltk, spacy\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| OS:\", platform.system())\n",
    "for name, mod in [\n",
    "    (\"numpy\", np), (\"pandas\", pd),\n",
    "    (\"sentence-transformers\", SentenceTransformer),\n",
    "    (\"transformers\", AutoTokenizer),\n",
    "    (\"spacy\", spacy), (\"nltk\", nltk),\n",
    "]:\n",
    "    try:\n",
    "        v = mod.__version__ if hasattr(mod, \"__version__\") else \"OK\"\n",
    "    except Exception:\n",
    "        v = \"OK\"\n",
    "    print(f\"{name:22s} -> {v}\")\n",
    "\n",
    "# Quick sanity check: load a tiny embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "sample = [\"hello world\", \"career in data science\"]\n",
    "emb = embedder.encode(sample, normalize_embeddings=True)\n",
    "print(\"Embeddings shape:\", emb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fc9db-8186-41f6-8d3e-8bbf14238b53",
   "metadata": {},
   "source": [
    "## Step 2 — Data Setup (2A: toy dataset)\n",
    "We’ll create a tiny in-notebook dataset to verify our flow before using a real Kaggle dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1078a7d4-c94b-442c-b71c-4304d61f9bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>patterns</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>[What skills do I need for data science?, How ...</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>[What do I need to study for AI?, What are AI ...</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>[What job is good for me if I like numbers?, I...</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>[Where should I start learning data analysis?,...</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greeting</td>\n",
       "      <td>[Hi, Hello, Hey]</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>[Bye, See you later, Goodbye]</td>\n",
       "      <td>Goodbye! Keep learning and stay curious!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        intent  \\\n",
       "0  ask_skills_for_data_science   \n",
       "1            ask_skills_for_ai   \n",
       "2       ask_job_recommendation   \n",
       "3            ask_learning_path   \n",
       "4                     greeting   \n",
       "5                      goodbye   \n",
       "\n",
       "                                            patterns  \\\n",
       "0  [What skills do I need for data science?, How ...   \n",
       "1  [What do I need to study for AI?, What are AI ...   \n",
       "2  [What job is good for me if I like numbers?, I...   \n",
       "3  [Where should I start learning data analysis?,...   \n",
       "4                                   [Hi, Hello, Hey]   \n",
       "5                      [Bye, See you later, Goodbye]   \n",
       "\n",
       "                                           responses  \n",
       "0  Data Science needs skills like Python, SQL, St...  \n",
       "1  AI requires knowledge of Python, Neural Networ...  \n",
       "2  You might enjoy careers like Data Analyst, Sta...  \n",
       "3  Start with Python, then learn data visualizati...  \n",
       "4                   Hello! How can I help you today?  \n",
       "5           Goodbye! Keep learning and stay curious!  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"intent\": [\n",
    "        \"ask_skills_for_data_science\",\n",
    "        \"ask_skills_for_ai\",\n",
    "        \"ask_job_recommendation\",\n",
    "        \"ask_learning_path\",\n",
    "        \"greeting\",\n",
    "        \"goodbye\",\n",
    "    ],\n",
    "    \"patterns\": [\n",
    "        [\"What skills do I need for data science?\", \"How to become a data scientist?\"],\n",
    "        [\"What do I need to study for AI?\", \"What are AI skills?\"],\n",
    "        [\"What job is good for me if I like numbers?\", \"I enjoy problem-solving, any job ideas?\"],\n",
    "        [\"Where should I start learning data analysis?\", \"Best way to learn machine learning?\"],\n",
    "        [\"Hi\", \"Hello\", \"Hey\"],\n",
    "        [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "    ],\n",
    "    \"responses\": [\n",
    "        \"Data Science needs skills like Python, SQL, Statistics, and Machine Learning.\",\n",
    "        \"AI requires knowledge of Python, Neural Networks, and Data Modeling.\",\n",
    "        \"You might enjoy careers like Data Analyst, Statistician, or Research Scientist.\",\n",
    "        \"Start with Python, then learn data visualization and basic machine learning.\",\n",
    "        \"Hello! How can I help you today?\",\n",
    "        \"Goodbye! Keep learning and stay curious!\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcacc4e3-4738-4002-a5a7-7f849479aadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What skills do I need for data science?</td>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to become a data scientist?</td>\n",
       "      <td>ask_skills_for_data_science</td>\n",
       "      <td>Data Science needs skills like Python, SQL, St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do I need to study for AI?</td>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are AI skills?</td>\n",
       "      <td>ask_skills_for_ai</td>\n",
       "      <td>AI requires knowledge of Python, Neural Networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What job is good for me if I like numbers?</td>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I enjoy problem-solving, any job ideas?</td>\n",
       "      <td>ask_job_recommendation</td>\n",
       "      <td>You might enjoy careers like Data Analyst, Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Where should I start learning data analysis?</td>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best way to learn machine learning?</td>\n",
       "      <td>ask_learning_path</td>\n",
       "      <td>Start with Python, then learn data visualizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "      <td>Hello! How can I help you today?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text                       intent  \\\n",
       "0       What skills do I need for data science?  ask_skills_for_data_science   \n",
       "1               How to become a data scientist?  ask_skills_for_data_science   \n",
       "2               What do I need to study for AI?            ask_skills_for_ai   \n",
       "3                           What are AI skills?            ask_skills_for_ai   \n",
       "4    What job is good for me if I like numbers?       ask_job_recommendation   \n",
       "5       I enjoy problem-solving, any job ideas?       ask_job_recommendation   \n",
       "6  Where should I start learning data analysis?            ask_learning_path   \n",
       "7           Best way to learn machine learning?            ask_learning_path   \n",
       "8                                            Hi                     greeting   \n",
       "9                                         Hello                     greeting   \n",
       "\n",
       "                                            response  \n",
       "0  Data Science needs skills like Python, SQL, St...  \n",
       "1  Data Science needs skills like Python, SQL, St...  \n",
       "2  AI requires knowledge of Python, Neural Networ...  \n",
       "3  AI requires knowledge of Python, Neural Networ...  \n",
       "4  You might enjoy careers like Data Analyst, Sta...  \n",
       "5  You might enjoy careers like Data Analyst, Sta...  \n",
       "6  Start with Python, then learn data visualizati...  \n",
       "7  Start with Python, then learn data visualizati...  \n",
       "8                   Hello! How can I help you today?  \n",
       "9                   Hello! How can I help you today?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    for pattern in row[\"patterns\"]:\n",
    "        rows.append({\"text\": pattern, \"intent\": row[\"intent\"], \"response\": row[\"responses\"]})\n",
    "\n",
    "chatbot_df = pd.DataFrame(rows)\n",
    "chatbot_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0465e62-2136-4052-bca5-c10f00ad4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: chatbot_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "chatbot_df.to_csv(\"chatbot_dataset.csv\", index=False)\n",
    "print(\"Saved: chatbot_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593f1b97-b2d4-4e54-a684-8c4d56d77205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: bleach in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\miniconda3\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.7.4.5 python-slugify-8.0.4 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fc66e3-824f-4bba-a50f-814cd322879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle config dir: C:\\Users\\hp\\projects\\intelligent-chatbot-notebook\\.kaggle\n",
      "Has kaggle.json: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.join(os.getcwd(), \".kaggle\")\n",
    "# Optional check:\n",
    "print(\"Kaggle config dir:\", os.environ[\"KAGGLE_CONFIG_DIR\"])\n",
    "print(\"Has kaggle.json:\", os.path.exists(os.path.join(os.environ[\"KAGGLE_CONFIG_DIR\"], \"kaggle.json\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68b5105-0419-4d40-90ab-6030e14757dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/elvinagammed/chatbots-intent-recognition-dataset\n",
      "License(s): copyright-authors\n",
      "Downloading chatbots-intent-recognition-dataset.zip to data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/16.9k [00:00<?, ?B/s]\n",
      "100%|##########| 16.9k/16.9k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d elvinagammed/chatbots-intent-recognition-dataset -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384ba518-f855-47ed-8ee1-6d75795682cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files:\n",
      "data\\chatbots-intent-recognition-dataset.zip\n",
      "data\\Intent.json\n"
     ]
    }
   ],
   "source": [
    "import zipfile, glob\n",
    "\n",
    "zip_path = sorted(glob.glob(\"data/*.zip\"))[0]\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(\"data\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "for p in glob.glob(\"data/**/*\", recursive=True):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f65be7-ca5e-4b37-83b5-0b2ce6eb261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intents']\n",
      "[{'context': {'clear': False, 'in': '', 'out': 'GreetingUserRequest'},\n",
      "  'entities': [],\n",
      "  'entityType': 'NA',\n",
      "  'extension': {'entities': False, 'function': '', 'responses': []},\n",
      "  'intent': 'Greeting',\n",
      "  'responses': ['Hi human, please tell me your GeniSys user',\n",
      "                'Hello human, please tell me your GeniSys user',\n",
      "                'Hola human, please tell me your GeniSys user'],\n",
      "  'text': ['Hi',\n",
      "           'Hi there',\n",
      "           'Hola',\n",
      "           'Hello',\n",
      "           'Hello there',\n",
      "           'Hya',\n",
      "           'Hya there']},\n",
      " {'context': {'clear': True, 'in': 'GreetingUserRequest', 'out': ''},\n",
      "  'entities': [{'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
      "               {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3}],\n",
      "  'entityType': 'NA',\n",
      "  'extension': {'entities': True,\n",
      "                'function': 'extensions.gHumans.updateHuman',\n",
      "                'responses': ['Hi %%HUMAN%%! How can I help?',\n",
      "                              'Hi %%HUMAN%%, how can I help you?',\n",
      "                              'Hello %%HUMAN%%, what can I do for you?',\n",
      "                              'Hola %%HUMAN%%, how can I help you?',\n",
      "                              'OK hi %%HUMAN%%, what can I do for you?']},\n",
      "  'intent': 'GreetingResponse',\n",
      "  'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
      "                'Good! Hi <HUMAN>, how can I help you?',\n",
      "                'Cool! Hello <HUMAN>, what can I do for you?',\n",
      "                'OK! Hola <HUMAN>, how can I help you?',\n",
      "                'OK! hi <HUMAN>, what can I do for you?'],\n",
      "  'text': ['My user is Adam',\n",
      "           'This is Adam',\n",
      "           'I am Adam',\n",
      "           'It is Adam',\n",
      "           'My user is Bella',\n",
      "           'This is Bella',\n",
      "           'I am Bella',\n",
      "           'It is Bella']}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: Load and preview the JSON\n",
    "with open(\"data/Intent.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Show the first few items so we can inspect structure\n",
    "if isinstance(data, dict):\n",
    "    # If it's a dictionary, show keys and sample content\n",
    "    pprint(list(data.keys()))\n",
    "    if \"intents\" in data:\n",
    "        pprint(data[\"intents\"][:2])\n",
    "    else:\n",
    "        pprint(data)\n",
    "else:\n",
    "    # If it's a list, show first 2 items\n",
    "    pprint(data[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1adf4bb-1e12-4a8c-b3ad-76b2b7e2a006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hola</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hello there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hya</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hya there</td>\n",
       "      <td>Hi human, please tell me your GeniSys user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>My user is Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>This is Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GreetingResponse</td>\n",
       "      <td>I am Adam</td>\n",
       "      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             intent          pattern  \\\n",
       "0          Greeting               Hi   \n",
       "1          Greeting         Hi there   \n",
       "2          Greeting             Hola   \n",
       "3          Greeting            Hello   \n",
       "4          Greeting      Hello there   \n",
       "5          Greeting              Hya   \n",
       "6          Greeting        Hya there   \n",
       "7  GreetingResponse  My user is Adam   \n",
       "8  GreetingResponse     This is Adam   \n",
       "9  GreetingResponse        I am Adam   \n",
       "\n",
       "                                     response  \n",
       "0  Hi human, please tell me your GeniSys user  \n",
       "1  Hi human, please tell me your GeniSys user  \n",
       "2  Hi human, please tell me your GeniSys user  \n",
       "3  Hi human, please tell me your GeniSys user  \n",
       "4  Hi human, please tell me your GeniSys user  \n",
       "5  Hi human, please tell me your GeniSys user  \n",
       "6  Hi human, please tell me your GeniSys user  \n",
       "7          Great! Hi <HUMAN>! How can I help?  \n",
       "8          Great! Hi <HUMAN>! How can I help?  \n",
       "9          Great! Hi <HUMAN>! How can I help?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for intent in data[\"intents\"]:\n",
    "    intent_name = intent.get(\"intent\", \"unknown\")\n",
    "    patterns = intent.get(\"text\", [])\n",
    "    responses = intent.get(\"responses\", [])\n",
    "    \n",
    "    # Make one row per text pattern\n",
    "    for pattern in patterns:\n",
    "        rows.append({\n",
    "            \"intent\": intent_name,\n",
    "            \"pattern\": pattern,\n",
    "            \"response\": responses[0] if responses else None\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392bb82e-c503-49cb-bc6c-3f978d7bf6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset as chatbot_intents_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"chatbot_intents_dataset.csv\", index=False)\n",
    "print(\"Saved cleaned dataset as chatbot_intents_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60895574-a528-4af7-9c2d-ef9589904314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
